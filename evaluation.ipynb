{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import data_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling 1297 none and 602 abusive label from davidson\n",
      "(1297, 40)\n",
      "(602, 40)\n",
      "split:test, label:none, data shape:(2594, 40)\n",
      "split:test, label:abusive, data shape:(3798, 40)\n"
     ]
    }
   ],
   "source": [
    "data_mixed_word, labels = data_helper.load_mixed_testset(\"word\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling 1297 none and 602 abusive label from davidson\n",
      "(1297, 140, 70)\n",
      "(602, 140, 70)\n",
      "split:test, label:none, data shape:(2594, 140, 70)\n",
      "split:test, label:abusive, data shape:(3798, 140, 70)\n"
     ]
    }
   ],
   "source": [
    "data_mixed_char, labels = data_helper.load_mixed_testset(\"char\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "abusive binary with davidson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added relabel to training set\n",
      "split:train, label:none, data shape:(14236, 40)\n",
      "split:train, label:abusive, data shape:(35590, 40)\n",
      "split:test, label:none, data shape:(1714, 40)\n",
      "split:test, label:abusive, data shape:(4378, 40)\n",
      "split:valid, label:none, data shape:(1713, 40)\n",
      "split:valid, label:abusive, data shape:(4375, 40)\n",
      "added relabel to training set\n",
      "split:train, label:none, data shape:(14236, 140, 70)\n",
      "split:train, label:abusive, data shape:(35590, 140, 70)\n",
      "split:test, label:none, data shape:(1714, 140, 70)\n",
      "split:test, label:abusive, data shape:(4378, 140, 70)\n",
      "split:valid, label:none, data shape:(1713, 140, 70)\n",
      "split:valid, label:abusive, data shape:(4375, 140, 70)\n"
     ]
    }
   ],
   "source": [
    "data_word_d, labels = data_helper.load_abusive_binary(\"word\", True)\n",
    "data_char_d, labels = data_helper.load_abusive_binary(\"char\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "abusive binary without davidson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added relabel to training set\n",
      "split:train, label:none, data shape:(10864, 40)\n",
      "split:train, label:abusive, data shape:(15665, 40)\n",
      "split:test, label:none, data shape:(1297, 40)\n",
      "split:test, label:abusive, data shape:(1899, 40)\n",
      "split:valid, label:none, data shape:(1297, 40)\n",
      "split:valid, label:abusive, data shape:(1897, 40)\n",
      "added relabel to training set\n",
      "split:train, label:none, data shape:(10864, 140, 70)\n",
      "split:train, label:abusive, data shape:(15665, 140, 70)\n",
      "split:test, label:none, data shape:(1297, 140, 70)\n",
      "split:test, label:abusive, data shape:(1899, 140, 70)\n",
      "split:valid, label:none, data shape:(1297, 140, 70)\n",
      "split:valid, label:abusive, data shape:(1897, 140, 70)\n"
     ]
    }
   ],
   "source": [
    "data_word_w, _ = data_helper.load_abusive_binary(\"word\", False)\n",
    "data_char_w, _ = data_helper.load_abusive_binary(\"char\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Abusive Classifier(first-step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_word = data_mixed_word[\"x_test\"]\n",
    "y_word = data_mixed_word[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_char = data_mixed_char[\"x_test\"]\n",
    "y_char = data_mixed_char[\"y_test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waasem Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none      0.692     0.570     0.625      2594\n",
      "    abusive      0.328     0.453     0.381      1204\n",
      "\n",
      "avg / total      0.577     0.533     0.548      3798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"./logs/waasem/word/weights.03.hdf5\")\n",
    "preds = model.predict(x_word, batch_size=128)\n",
    "print(classification_report(np.argmax(y_word, axis=1), np.argmax(preds, axis=1), digits=3, target_names=labels))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waasem Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none      0.695     0.564     0.623      2594\n",
      "    abusive      0.332     0.468     0.388      1204\n",
      "\n",
      "avg / total      0.580     0.533     0.548      3798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"./logs/waasem/hybrid/weights.04.hdf5\")\n",
    "preds = model.predict([x_char, x_word], batch_size=128)\n",
    "print(classification_report(np.argmax(y_word, axis=1), np.argmax(preds, axis=1), digits=3, target_names=labels))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Davidson Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none      0.909     0.907     0.908      2594\n",
      "    abusive      0.801     0.805     0.803      1204\n",
      "\n",
      "avg / total      0.875     0.875     0.875      3798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"./logs/davidson/word/weights.02.hdf5\")\n",
    "preds = model.predict(x_word, batch_size=128)\n",
    "print(classification_report(np.argmax(y_word, axis=1), np.argmax(preds, axis=1), digits=3, target_names=labels))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Davidson Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none      0.919     0.893     0.906      2594\n",
      "    abusive      0.782     0.830     0.805      1204\n",
      "\n",
      "avg / total      0.875     0.873     0.874      3798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"./logs/davidson/hybrid/weights.02.hdf5\")\n",
    "preds = model.predict([x_char, x_word], batch_size=128)\n",
    "print(classification_report(np.argmax(y_word, axis=1), np.argmax(preds, axis=1), digits=3, target_names=labels))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none      0.917     0.882     0.899      2594\n",
      "    abusive      0.766     0.828     0.796      1204\n",
      "\n",
      "avg / total      0.869     0.865     0.867      3798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"/home/homes/jhpark/hate-speech/logs/pretrain/word/weights.05.hdf5\")\n",
    "preds = model.predict(x_word, batch_size=128)\n",
    "print(classification_report(np.argmax(y_word, axis=1), np.argmax(preds, axis=1), digits=3, target_names=labels))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none      0.918     0.925     0.921      2594\n",
      "    abusive      0.836     0.821     0.829      1204\n",
      "\n",
      "avg / total      0.892     0.892     0.892      3798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"/home/homes/jhpark/hate-speech/logs/pretrain/hybrid/weights.12.hdf5\")\n",
    "preds = model.predict([x_char, x_word], batch_size=128)\n",
    "print(classification_report(np.argmax(y_word, axis=1), np.argmax(preds, axis=1), digits=3, target_names=labels))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train Sexism-racism classifier(second-step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from model.helper import calculate_metrics\n",
    "import numpy as np\n",
    "from data.preprocess import load_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded preprocessed tweets for sexism:3152\n",
      "loaded preprocessed tweets for racism:1649\n",
      "loaded preprocessed tweets for sexism:394\n",
      "loaded preprocessed tweets for racism:206\n",
      "loaded preprocessed tweets for sexism:395\n",
      "loaded preprocessed tweets for racism:207\n"
     ]
    }
   ],
   "source": [
    "original_data = load_from_file(\"waasem\", [\"sexism\", \"racism\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split:train, label:sexism\n",
      "split:train, label:racism\n",
      "split:test, label:sexism\n",
      "split:test, label:racism\n",
      "split:valid, label:sexism\n",
      "split:valid, label:racism\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for split in original_data.keys():\n",
    "    x = \"x_\" + split\n",
    "    y = \"y_\" + split\n",
    "    data[x] = None\n",
    "    data[y] = []\n",
    "    for i, label in enumerate([\"sexism\", \"racism\"]):\n",
    "        _data = original_data[split][label]\n",
    "        if data[x] is not None:\n",
    "            data[x] += _data\n",
    "        else:\n",
    "            data[x] = _data\n",
    "        print(\"split:%s, label:%s\" % (split, label))\n",
    "        data[y] += [i+1 for _ in range(len(_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<user> bet i can prove that you , like most feminists , oppose equality quickly , a b or c ? women against feminism <url>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"x_train\"] = [\" \".join(str(v) for v in row) for row in data[\"x_train\"]]\n",
    "data[\"x_train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt <user> : <user> oh no ! heaven forbid a man finds a woman visually appealing ! the horror ! grow up . not sexist free speech science'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"x_test\"] = [\" \".join(str(v) for v in row) for row in data[\"x_test\"]]\n",
    "data[\"x_test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<user> being a fuckface to a girl who just agreed , she doesn't want a feminazi hoe in her business , so fuck off .\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"x_valid\"] = [\" \".join(str(v) for v in row) for row in data[\"x_valid\"]]\n",
    "data[\"x_valid\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(602, 602)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[\"x_test\"]), len(data[\"y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(2,5), analyzer=\"char\")),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(solver=\"sag\"))])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
       "        strip... penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(data[\"x_train\"], data[\"y_train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_preds = text_clf.predict(data[\"x_train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     sexism      0.963     0.997     0.980      3152\n",
      "     racism      0.993     0.927     0.959      1649\n",
      "\n",
      "avg / total      0.973     0.973     0.972      4801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data[\"y_train\"], train_preds, \n",
    "                            digits=3, target_names=[\"sexism\", \"racism\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     sexism      0.933     0.985     0.958       395\n",
      "     racism      0.968     0.865     0.913       207\n",
      "\n",
      "avg / total      0.945     0.944     0.943       602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_preds = text_clf.predict(data[\"x_test\"])\n",
    "print(classification_report(data[\"y_test\"], test_preds, \n",
    "                            digits=3, target_names=[\"sexism\", \"racism\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluate Two-step classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_helper import load_waasem, load_multiclass\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_word_d = load_waasem(\"./data/word_outputs/\")\n",
    "data_char_d = load_waasem(\"./data/char_outputs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded preprocessed tweets for none:10376\n",
      "loaded preprocessed tweets for sexism:3152\n",
      "loaded preprocessed tweets for racism:1649\n",
      "loaded preprocessed tweets for none:1297\n",
      "loaded preprocessed tweets for sexism:394\n",
      "loaded preprocessed tweets for racism:206\n",
      "loaded preprocessed tweets for none:1297\n",
      "loaded preprocessed tweets for sexism:395\n",
      "loaded preprocessed tweets for racism:207\n"
     ]
    }
   ],
   "source": [
    "raw_data = load_from_file(\"waasem\", [\"none\", \"sexism\", \"racism\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"./data/word_outputs/vocab.pkl\", \"rb\") as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['. <user> <user> <user> . <repeat> feminism would only have a name issue . PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD',\n",
       " '<user> please answer . <repeat> <url> PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD',\n",
       " 'suck shit kat you vile , UNK , nasty bitch ! giving shit to annie and lloyd , only to be told your dish was gross ! karma bitch ! mkr PAD PAD PAD PAD PAD PAD PAD PAD PAD',\n",
       " \"rt <user> : and don't call me sexist for that last tweet . if women want equal praise for success , they gotta take equal blame for UNK … PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\",\n",
       " \"rt <user> : some woman was proper staring at me whilst i was parking my car . it's ok babe , i male therefore i can drive . not sexist truth PAD PAD PAD PAD PAD PAD PAD PAD PAD\"]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\" \".join([vocab[\"id2word\"][token] for token in row]) for row in data_word_d[\"test\"][\"sexism\"][-5:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['. <user> <user> <user> . <repeat> feminism would only have a name issue .',\n",
       " '<user> please answer . <repeat> <url>',\n",
       " 'suck shit kat you vile , venomous , nasty bitch ! giving shit to annie and lloyd , only to be told your dish was gross ! karma bitch ! mkr',\n",
       " \"rt <user> : and don't call me sexist for that last tweet . if women want equal praise for success , they gotta take equal blame for failur …\",\n",
       " \"rt <user> : some woman was proper staring at me whilst i was parking my car . it's ok babe , i male therefore i can drive . not sexist truth\"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\" \".join(row) for row in raw_data[\"test\"][\"sexism\"][-5:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1297, 40)\n",
      "(1297, 140, 70)\n",
      "(1692, 40)\n",
      "(1692, 140, 70)\n",
      "(1899, 40)\n",
      "(1899, 140, 70)\n"
     ]
    }
   ],
   "source": [
    "x_word = None\n",
    "x_char = None\n",
    "x_text = []\n",
    "y_test = []\n",
    "for i, label in enumerate([\"none\", \"sexism\", \"racism\"]):\n",
    "    assert len(data_word_d[\"test\"][label]) == len(data_char_d[\"test\"][label]) \n",
    "    assert len(data_word_d[\"test\"][label]) == len(raw_data[\"test\"][label])\n",
    "    if x_word is None:\n",
    "        x_word = data_word_d[\"test\"][label]\n",
    "    else:\n",
    "        x_word = np.vstack((x_word, data_word_d[\"test\"][label]))\n",
    "    print(x_word.shape)\n",
    "    \n",
    "    if x_char is None:\n",
    "        x_char = data_char_d[\"test\"][label]\n",
    "    else:\n",
    "        x_char = np.vstack((x_char, data_char_d[\"test\"][label]))\n",
    "    print(x_char.shape)\n",
    "    \n",
    "    x_text += raw_data[\"test\"][label]\n",
    "    \n",
    "    y_test += [i for _ in range(len(raw_data[\"test\"][label]))]\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waasem Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none      0.688     0.528     0.597      1297\n",
      "     sexism      0.254     0.476     0.331       395\n",
      "     racism      0.534     0.420     0.470       207\n",
      "\n",
      "avg / total      0.581     0.506     0.528      1899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"./logs/waasem/word/weights.03.hdf5\")\n",
    "preds = np.argmax(model.predict(x_word, batch_size=128), axis=1)\n",
    "for i, pred in enumerate(preds):\n",
    "    if pred != 0:\n",
    "        preds[i] = text_clf.predict([\" \".join(x_text[i])])\n",
    "print(classification_report(np.argmax(y_test, axis=1), preds, \n",
    "                            digits=3, target_names=[\"none\", \"sexism\", \"racism\"]))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waasem Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none      0.700     0.527     0.602      1297\n",
      "     sexism      0.260     0.491     0.340       395\n",
      "     racism      0.542     0.464     0.500       207\n",
      "\n",
      "avg / total      0.591     0.513     0.536      1899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"./logs/waasem/hybrid/weights.04.hdf5\")\n",
    "preds = np.argmax(model.predict([x_char, x_word], batch_size=128), axis=1)\n",
    "for i, pred in enumerate(preds):\n",
    "    if pred != 0:\n",
    "        preds[i] = text_clf.predict([\" \".join(x_text[i])])\n",
    "print(classification_report(np.argmax(y_test, axis=1), preds, \n",
    "                            digits=3, target_names=[\"none\", \"sexism\", \"racism\"]))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Davidson Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none      0.838     0.899     0.867      1297\n",
      "     sexism      0.720     0.572     0.638       395\n",
      "     racism      0.705     0.657     0.680       207\n",
      "\n",
      "avg / total      0.799     0.805     0.799      1899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"./logs/davidson/word/weights.01.hdf5\")\n",
    "preds = np.argmax(model.predict(x_word, batch_size=128), axis=1)\n",
    "for i, pred in enumerate(preds):\n",
    "    if pred != 0:\n",
    "        preds[i] = text_clf.predict([\" \".join(x_text[i])])\n",
    "print(classification_report(np.argmax(y_test, axis=1), preds, \n",
    "                            digits=3, target_names=[\"none\", \"sexism\", \"racism\"]))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Davidson Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none      0.865     0.876     0.870      1297\n",
      "     sexism      0.691     0.656     0.673       395\n",
      "     racism      0.697     0.710     0.703       207\n",
      "\n",
      "avg / total      0.811     0.812     0.811      1899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"./logs/davidson/hybrid/weights.02.hdf5\")\n",
    "preds = np.argmax(model.predict([x_char, x_word], batch_size=128), axis=1)\n",
    "for i, pred in enumerate(preds):\n",
    "    if pred != 0:\n",
    "        preds[i] = text_clf.predict([\" \".join(x_text[i])])\n",
    "print(classification_report(np.argmax(y_test, axis=1), preds, \n",
    "                            digits=3, target_names=[\"none\", \"sexism\", \"racism\"]))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pretrain word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none      0.867     0.873     0.870      1297\n",
      "     sexism      0.679     0.663     0.671       395\n",
      "     racism      0.696     0.696     0.696       207\n",
      "\n",
      "avg / total      0.809     0.810     0.809      1899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"/home/homes/jhpark/hate-speech/logs/pretrain/word/weights.05.hdf5\")\n",
    "preds = np.argmax(model.predict(x_word, batch_size=128), axis=1)\n",
    "for i, pred in enumerate(preds):\n",
    "    if pred != 0:\n",
    "        preds[i] = text_clf.predict([\" \".join(x_text[i])])\n",
    "print(classification_report(np.argmax(y_test, axis=1), preds, \n",
    "                            digits=3, target_names=[\"none\", \"sexism\", \"racism\"]))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pretrain hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none      0.859     0.911     0.884      1297\n",
      "     sexism      0.736     0.648     0.689       395\n",
      "     racism      0.766     0.647     0.702       207\n",
      "\n",
      "avg / total      0.823     0.828     0.824      1899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"/home/homes/jhpark/hate-speech/logs/pretrain/hybrid/weights.12.hdf5\")\n",
    "preds = np.argmax(model.predict([x_char, x_word], batch_size=128), axis=1)\n",
    "for i, pred in enumerate(preds):\n",
    "    if pred != 0:\n",
    "        preds[i] = text_clf.predict([\" \".join(x_text[i])])\n",
    "print(classification_report(np.argmax(y_test, axis=1), preds, \n",
    "                            digits=3, target_names=[\"none\", \"sexism\", \"racism\"]))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
