{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import data_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling 1277 none and 601 abusive label from davidson\n",
      "(1277, 40)\n",
      "(601, 40)\n",
      "split:test, label:none, data shape:(2554, 40)\n",
      "split:test, label:abusive, data shape:(3756, 40)\n"
     ]
    }
   ],
   "source": [
    "data_mixed_word, labels = data_helper.load_mixed_testset(\"word\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling 1277 none and 601 abusive label from davidson\n",
      "(1277, 140, 70)\n",
      "(601, 140, 70)\n",
      "split:test, label:none, data shape:(2554, 140, 70)\n",
      "split:test, label:abusive, data shape:(3756, 140, 70)\n"
     ]
    }
   ],
   "source": [
    "data_mixed_char, labels = data_helper.load_mixed_testset(\"char\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "abusive binary with davidson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split:train, label:none, data shape:(13539, 40)\n",
      "split:train, label:abusive, data shape:(34886, 40)\n",
      "split:test, label:none, data shape:(1694, 40)\n",
      "split:test, label:abusive, data shape:(4357, 40)\n",
      "split:valid, label:none, data shape:(1734, 40)\n",
      "split:valid, label:abusive, data shape:(4417, 40)\n",
      "split:train, label:none, data shape:(13539, 140, 70)\n",
      "split:train, label:abusive, data shape:(34886, 140, 70)\n",
      "split:test, label:none, data shape:(1694, 140, 70)\n",
      "split:test, label:abusive, data shape:(4357, 140, 70)\n",
      "split:valid, label:none, data shape:(1734, 140, 70)\n",
      "split:valid, label:abusive, data shape:(4417, 140, 70)\n"
     ]
    }
   ],
   "source": [
    "data_word_d, labels = data_helper.load_abusive_binary(\"word\", True)\n",
    "data_char_d, labels = data_helper.load_abusive_binary(\"char\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "abusive binary without davidson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split:train, label:none, data shape:(10209, 40)\n",
      "split:train, label:abusive, data shape:(15010, 40)\n",
      "split:test, label:none, data shape:(1277, 40)\n",
      "split:test, label:abusive, data shape:(1878, 40)\n",
      "split:valid, label:none, data shape:(1276, 40)\n",
      "split:valid, label:abusive, data shape:(1876, 40)\n",
      "split:train, label:none, data shape:(10209, 140, 70)\n",
      "split:train, label:abusive, data shape:(15010, 140, 70)\n",
      "split:test, label:none, data shape:(1277, 140, 70)\n",
      "split:test, label:abusive, data shape:(1878, 140, 70)\n",
      "split:valid, label:none, data shape:(1276, 140, 70)\n",
      "split:valid, label:abusive, data shape:(1876, 140, 70)\n"
     ]
    }
   ],
   "source": [
    "data_word_w, _ = data_helper.load_abusive_binary(\"word\", False)\n",
    "data_char_w, _ = data_helper.load_abusive_binary(\"char\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Abusive Classifier(first-step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_word = data_mixed_word[\"x_test\"]\n",
    "y_word = data_mixed_word[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_char = data_mixed_char[\"x_test\"]\n",
    "y_char = data_mixed_char[\"y_test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waasem Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none      0.853     0.905     0.878      2554\n",
      "    abusive      0.768     0.668     0.715      1202\n",
      "\n",
      "avg / total      0.826     0.829     0.826      3756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"./logs/waasem/word/weights.03.hdf5\")\n",
    "preds = model.predict(x_word, batch_size=128)\n",
    "print(classification_report(np.argmax(y_word, axis=1), np.argmax(preds, axis=1), digits=3, target_names=labels))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waasem Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none      0.864     0.890     0.877      2554\n",
      "    abusive      0.750     0.703     0.726      1202\n",
      "\n",
      "avg / total      0.828     0.830     0.829      3756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"./logs/waasem/hybrid/weights.04.hdf5\")\n",
    "preds = model.predict([x_char, x_word], batch_size=128)\n",
    "print(classification_report(np.argmax(y_word, axis=1), np.argmax(preds, axis=1), digits=3, target_names=labels))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Davidson Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none      0.902     0.904     0.903      2554\n",
      "    abusive      0.796     0.791     0.793      1202\n",
      "\n",
      "avg / total      0.868     0.868     0.868      3756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"./logs/davidson/word/weights.01.hdf5\")\n",
    "preds = model.predict(x_word, batch_size=128)\n",
    "print(classification_report(np.argmax(y_word, axis=1), np.argmax(preds, axis=1), digits=3, target_names=labels))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Davidson Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none      0.896     0.897     0.897      2554\n",
      "    abusive      0.781     0.778     0.779      1202\n",
      "\n",
      "avg / total      0.859     0.859     0.859      3756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"./logs/davidson/hybrid/weights.02.hdf5\")\n",
    "preds = model.predict([x_char, x_word], batch_size=128)\n",
    "print(classification_report(np.argmax(y_word, axis=1), np.argmax(preds, axis=1), digits=3, target_names=labels))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train Sexism-racism classifier(second-step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from model.helper import calculate_metrics\n",
    "import numpy as np\n",
    "from data.preprocess import load_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded preprocessed tweets for sexism:3152\n",
      "loaded preprocessed tweets for racism:1649\n",
      "loaded preprocessed tweets for sexism:394\n",
      "loaded preprocessed tweets for racism:206\n",
      "loaded preprocessed tweets for sexism:394\n",
      "loaded preprocessed tweets for racism:207\n"
     ]
    }
   ],
   "source": [
    "original_data = load_from_file(\"waasem\", [\"sexism\", \"racism\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split:train, label:sexism\n",
      "split:train, label:racism\n",
      "split:test, label:sexism\n",
      "split:test, label:racism\n",
      "split:valid, label:sexism\n",
      "split:valid, label:racism\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for split in original_data.keys():\n",
    "    x = \"x_\" + split\n",
    "    y = \"y_\" + split\n",
    "    data[x] = None\n",
    "    data[y] = []\n",
    "    for i, label in enumerate([\"sexism\", \"racism\"]):\n",
    "        _data = original_data[split][label]\n",
    "        if data[x] is not None:\n",
    "            data[x] += _data\n",
    "        else:\n",
    "            data[x] = _data\n",
    "        print(\"split:%s, label:%s\" % (split, label))\n",
    "        data[y] += [i+1 for _ in range(len(_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kat is actually psychotic . off mkr into a psychiatric ward mkr'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"x_train\"] = [\" \".join(str(v) for v in row) for row in data[\"x_train\"]]\n",
    "data[\"x_train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\": i'm not sexist , but women are inferior . proving that you can still be an idiot regardless of your …\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"x_test\"] = [\" \".join(str(v) for v in row) for row in data[\"x_test\"]]\n",
    "data[\"x_test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"thk u for standing up to the feminazi bullies . checked out your music and it's pretty fucking sweet . hope to see you in nj .\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"x_valid\"] = [\" \".join(str(v) for v in row) for row in data[\"x_valid\"]]\n",
    "data[\"x_valid\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(601, 601)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[\"x_test\"]), len(data[\"y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(2,5), analyzer=\"char\")),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(solver=\"sag\"))])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
       "        strip... penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(data[\"x_train\"], data[\"y_train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_preds = text_clf.predict(data[\"x_train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     sexism      0.957     0.998     0.977      3152\n",
      "     racism      0.996     0.914     0.953      1649\n",
      "\n",
      "avg / total      0.970     0.969     0.969      4801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data[\"y_train\"], train_preds, \n",
    "                            digits=3, target_names=[\"sexism\", \"racism\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     sexism      0.927     0.992     0.958       394\n",
      "     racism      0.983     0.850     0.912       207\n",
      "\n",
      "avg / total      0.946     0.943     0.942       601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_preds = text_clf.predict(data[\"x_test\"])\n",
    "print(classification_report(data[\"y_test\"], test_preds, \n",
    "                            digits=3, target_names=[\"sexism\", \"racism\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluate Two-step classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_helper import load_waasem, load_multiclass\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_word_d = load_waasem(\"./data/word_outputs/\")\n",
    "data_char_d = load_waasem(\"./data/char_outputs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded preprocessed tweets for none:10209\n",
      "loaded preprocessed tweets for sexism:3152\n",
      "loaded preprocessed tweets for racism:1649\n",
      "loaded preprocessed tweets for none:1276\n",
      "loaded preprocessed tweets for sexism:394\n",
      "loaded preprocessed tweets for racism:206\n",
      "loaded preprocessed tweets for none:1277\n",
      "loaded preprocessed tweets for sexism:394\n",
      "loaded preprocessed tweets for racism:207\n"
     ]
    }
   ],
   "source": [
    "raw_data = load_from_file(\"waasem\", [\"none\", \"sexism\", \"racism\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"./data/word_outputs/vocab.pkl\", \"rb\") as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how annoying is this kat on mkr PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD',\n",
       " \"maybe you don't like it that much . id like to consider myself open minded . and not sexist . but ... female ufc ? what in the fuck PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\",\n",
       " ': call me sexist all you want , but from stories / seeing this kind of stuff go down , women as a whole need to change how they co … PAD PAD PAD PAD PAD PAD PAD PAD PAD',\n",
       " 'men\\'s \" logic \" , ladies and UNK i don\\'t UNK women over men . i\\'m not sexist therefore i\\'m not a feminist . PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD',\n",
       " 'i hate the blameonenotall campaign i know not all men are rapists but all men benefit from male privilege and all men are guilty of sexism PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\" \".join([vocab[\"id2word\"][token] for token in row]) for row in data_word_d[\"test\"][\"sexism\"][-5:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how annoying is this kat on mkr',\n",
       " \"maybe you don't like it that much . id like to consider myself open minded . and not sexist . but ... female ufc ? what in the fuck\",\n",
       " ': call me sexist all you want , but from stories / seeing this kind of stuff go down , women as a whole need to change how they co …',\n",
       " 'men\\'s \" logic \" , ladies and gentlemen i don\\'t prioritize women over men . i\\'m not sexist therefore i\\'m not a feminist .',\n",
       " 'i hate the blameonenotall campaign i know not all men are rapists but all men benefit from male privilege and all men are guilty of sexism']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\" \".join(row) for row in raw_data[\"test\"][\"sexism\"][-5:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1277, 40)\n",
      "(1277, 140, 70)\n",
      "(1671, 40)\n",
      "(1671, 140, 70)\n",
      "(1878, 40)\n",
      "(1878, 140, 70)\n"
     ]
    }
   ],
   "source": [
    "x_word = None\n",
    "x_char = None\n",
    "x_text = []\n",
    "y_test = []\n",
    "for i, label in enumerate([\"none\", \"sexism\", \"racism\"]):\n",
    "    assert len(data_word_d[\"test\"][label]) == len(data_char_d[\"test\"][label]) \n",
    "    assert len(data_word_d[\"test\"][label]) == len(raw_data[\"test\"][label])\n",
    "    if x_word is None:\n",
    "        x_word = data_word_d[\"test\"][label]\n",
    "    else:\n",
    "        x_word = np.vstack((x_word, data_word_d[\"test\"][label]))\n",
    "    print(x_word.shape)\n",
    "    \n",
    "    if x_char is None:\n",
    "        x_char = data_char_d[\"test\"][label]\n",
    "    else:\n",
    "        x_char = np.vstack((x_char, data_char_d[\"test\"][label]))\n",
    "    print(x_char.shape)\n",
    "    \n",
    "    x_text += raw_data[\"test\"][label]\n",
    "    \n",
    "    y_test += [i for _ in range(len(raw_data[\"test\"][label]))]\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waasem Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none      0.855     0.908     0.880      1277\n",
      "     sexism      0.745     0.622     0.678       394\n",
      "     racism      0.767     0.715     0.740       207\n",
      "\n",
      "avg / total      0.822     0.826     0.822      1878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"./logs/waasem/word/weights.03.hdf5\")\n",
    "preds = np.argmax(model.predict(x_word, batch_size=128), axis=1)\n",
    "for i, pred in enumerate(preds):\n",
    "    if pred != 0:\n",
    "        preds[i] = text_clf.predict([\" \".join(x_text[i])])\n",
    "print(classification_report(np.argmax(y_test, axis=1), preds, \n",
    "                            digits=3, target_names=[\"none\", \"sexism\", \"racism\"]))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waasem Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none      0.861     0.908     0.884      1277\n",
      "     sexism      0.732     0.632     0.678       394\n",
      "     racism      0.786     0.729     0.757       207\n",
      "\n",
      "avg / total      0.826     0.830     0.827      1878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"./logs/waasem/hybrid/weights.04.hdf5\")\n",
    "preds = np.argmax(model.predict([x_char, x_word], batch_size=128), axis=1)\n",
    "for i, pred in enumerate(preds):\n",
    "    if pred != 0:\n",
    "        preds[i] = text_clf.predict([\" \".join(x_text[i])])\n",
    "print(classification_report(np.argmax(y_test, axis=1), preds, \n",
    "                            digits=3, target_names=[\"none\", \"sexism\", \"racism\"]))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Davidson Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none      0.839     0.900     0.868      1277\n",
      "     sexism      0.704     0.574     0.632       394\n",
      "     racism      0.761     0.691     0.724       207\n",
      "\n",
      "avg / total      0.802     0.808     0.803      1878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"./logs/davidson/word/weights.01.hdf5\")\n",
    "preds = np.argmax(model.predict(x_word, batch_size=128), axis=1)\n",
    "for i, pred in enumerate(preds):\n",
    "    if pred != 0:\n",
    "        preds[i] = text_clf.predict([\" \".join(x_text[i])])\n",
    "print(classification_report(np.argmax(y_test, axis=1), preds, \n",
    "                            digits=3, target_names=[\"none\", \"sexism\", \"racism\"]))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Davidson Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none      0.831     0.908     0.868      1277\n",
      "     sexism      0.711     0.569     0.632       394\n",
      "     racism      0.775     0.633     0.697       207\n",
      "\n",
      "avg / total      0.800     0.806     0.799      1878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"./logs/davidson/hybrid/weights.02.hdf5\")\n",
    "preds = np.argmax(model.predict([x_char, x_word], batch_size=128), axis=1)\n",
    "for i, pred in enumerate(preds):\n",
    "    if pred != 0:\n",
    "        preds[i] = text_clf.predict([\" \".join(x_text[i])])\n",
    "print(classification_report(np.argmax(y_test, axis=1), preds, \n",
    "                            digits=3, target_names=[\"none\", \"sexism\", \"racism\"]))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
