nohup: ignoring input
Using TensorFlow backend.
{'batch_size': 32, 'logdir': 'davidson/hybrid', 'learning_rate': 0.0001, 'char_filter_sizes': '3,4,5', 'num_filters': 50, 'word_filter_sizes': '1,2,3', 'model_name': 'hybrid_cnn', 'include_davidson': True, 'num_epochs': 10}
split:test, label:none, data shape:(1694, 40)
split:test, label:abusive, data shape:(4357, 40)
split:valid, label:none, data shape:(1734, 40)
split:valid, label:abusive, data shape:(4417, 40)
split:train, label:none, data shape:(13539, 40)
split:train, label:abusive, data shape:(34886, 40)
split:test, label:none, data shape:(1694, 140, 70)
split:test, label:abusive, data shape:(4357, 140, 70)
split:valid, label:none, data shape:(1734, 140, 70)
split:valid, label:abusive, data shape:(4417, 140, 70)
split:train, label:none, data shape:(13539, 140, 70)
split:train, label:abusive, data shape:(34886, 140, 70)
vocabulary loaded with 13859 words
word_len: 40, char_len: 140
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input_1 (InputLayer)             (None, 40)            0                                            
____________________________________________________________________________________________________
embedding_1 (Embedding)          (None, 40, 300)       4157700     input_1[0][0]                    
____________________________________________________________________________________________________
input_2 (InputLayer)             (None, 140, 70)       0                                            
____________________________________________________________________________________________________
conv1d_1 (Conv1D)                (None, 40, 50)        15050       embedding_1[0][0]                
____________________________________________________________________________________________________
conv1d_2 (Conv1D)                (None, 39, 50)        30050       embedding_1[0][0]                
____________________________________________________________________________________________________
conv1d_3 (Conv1D)                (None, 38, 50)        45050       embedding_1[0][0]                
____________________________________________________________________________________________________
conv1d_4 (Conv1D)                (None, 138, 50)       10550       input_2[0][0]                    
____________________________________________________________________________________________________
conv1d_5 (Conv1D)                (None, 137, 50)       14050       input_2[0][0]                    
____________________________________________________________________________________________________
conv1d_6 (Conv1D)                (None, 136, 50)       17550       input_2[0][0]                    
____________________________________________________________________________________________________
max_pooling1d_1 (MaxPooling1D)   (None, 1, 50)         0           conv1d_1[0][0]                   
____________________________________________________________________________________________________
max_pooling1d_2 (MaxPooling1D)   (None, 1, 50)         0           conv1d_2[0][0]                   
____________________________________________________________________________________________________
max_pooling1d_3 (MaxPooling1D)   (None, 1, 50)         0           conv1d_3[0][0]                   
____________________________________________________________________________________________________
max_pooling1d_4 (MaxPooling1D)   (None, 1, 50)         0           conv1d_4[0][0]                   
____________________________________________________________________________________________________
max_pooling1d_5 (MaxPooling1D)   (None, 1, 50)         0           conv1d_5[0][0]                   
____________________________________________________________________________________________________
max_pooling1d_6 (MaxPooling1D)   (None, 1, 50)         0           conv1d_6[0][0]                   
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 50)            0           max_pooling1d_1[0][0]            
____________________________________________________________________________________________________
flatten_2 (Flatten)              (None, 50)            0           max_pooling1d_2[0][0]            
____________________________________________________________________________________________________
flatten_3 (Flatten)              (None, 50)            0           max_pooling1d_3[0][0]            
____________________________________________________________________________________________________
flatten_4 (Flatten)              (None, 50)            0           max_pooling1d_4[0][0]            
____________________________________________________________________________________________________
flatten_5 (Flatten)              (None, 50)            0           max_pooling1d_5[0][0]            
____________________________________________________________________________________________________
flatten_6 (Flatten)              (None, 50)            0           max_pooling1d_6[0][0]            
____________________________________________________________________________________________________
concatenate_1 (Concatenate)      (None, 300)           0           flatten_1[0][0]                  
                                                                   flatten_2[0][0]                  
                                                                   flatten_3[0][0]                  
                                                                   flatten_4[0][0]                  
                                                                   flatten_5[0][0]                  
                                                                   flatten_6[0][0]                  
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 300)           0           concatenate_1[0][0]              
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 2)             602         dropout_1[0][0]                  
====================================================================================================
Total params: 4,290,602
Trainable params: 4,290,602
Non-trainable params: 0
____________________________________________________________________________________________________
Train on 34886 samples, validate on 4417 samples
2017-07-17 10:58:52.576046: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-17 10:58:52.576084: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-17 10:58:52.576095: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-17 10:58:52.576102: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-17 10:58:52.576110: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-07-17 10:58:53.131836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla M60
major: 5 minor: 2 memoryClockRate (GHz) 1.1775
pciBusID 0000:85:00.0
Total memory: 7.43GiB
Free memory: 7.36GiB
2017-07-17 10:58:53.131892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2017-07-17 10:58:53.131915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2017-07-17 10:58:53.131932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:85:00.0)
Epoch 1/10
Generating Classification Report:
  32/4417 [..............................] - ETA: 7s 448/4417 [==>...........................] - ETA: 0s 896/4417 [=====>........................] - ETA: 0s1312/4417 [=======>......................] - ETA: 0s1728/4417 [==========>...................] - ETA: 0s2144/4417 [=============>................] - ETA: 0s2560/4417 [================>.............] - ETA: 0s2976/4417 [===================>..........] - ETA: 0s3392/4417 [======================>.......] - ETA: 0s3808/4417 [========================>.....] - ETA: 0s4256/4417 [===========================>..] - ETA: 0s
             precision    recall  f1-score   support

       none       0.81      0.92      0.86      1734
    abusive       0.94      0.86      0.90      2683

avg / total       0.89      0.89      0.89      4417


Epoch 00000: val_acc improved from -inf to 0.88522, saving model to /home/homes/jhpark/hate-speech/logs/davidson/hybrid/weights.00.hdf5
22s - loss: 0.3725 - acc: 0.8230 - val_loss: 0.2733 - val_acc: 0.8852
Epoch 2/10
Generating Classification Report:
  32/4417 [..............................] - ETA: 0s 448/4417 [==>...........................] - ETA: 0s 864/4417 [====>.........................] - ETA: 0s1280/4417 [=======>......................] - ETA: 0s1664/4417 [==========>...................] - ETA: 0s2080/4417 [=============>................] - ETA: 0s2496/4417 [===============>..............] - ETA: 0s2880/4417 [==================>...........] - ETA: 0s3296/4417 [=====================>........] - ETA: 0s3680/4417 [=======================>......] - ETA: 0s4096/4417 [==========================>...] - ETA: 0s
             precision    recall  f1-score   support

       none       0.83      0.91      0.87      1734
    abusive       0.94      0.88      0.91      2683

avg / total       0.89      0.89      0.89      4417


Epoch 00001: val_acc improved from 0.88522 to 0.88997, saving model to /home/homes/jhpark/hate-speech/logs/davidson/hybrid/weights.01.hdf5
18s - loss: 0.2433 - acc: 0.8967 - val_loss: 0.2550 - val_acc: 0.8900
Epoch 3/10
Generating Classification Report:
  32/4417 [..............................] - ETA: 0s 480/4417 [==>...........................] - ETA: 0s 896/4417 [=====>........................] - ETA: 0s1312/4417 [=======>......................] - ETA: 0s1728/4417 [==========>...................] - ETA: 0s2144/4417 [=============>................] - ETA: 0s2560/4417 [================>.............] - ETA: 0s2976/4417 [===================>..........] - ETA: 0s3392/4417 [======================>.......] - ETA: 0s3840/4417 [=========================>....] - ETA: 0s4256/4417 [===========================>..] - ETA: 0s
             precision    recall  f1-score   support

       none       0.83      0.91      0.87      1734
    abusive       0.94      0.88      0.91      2683

avg / total       0.90      0.89      0.89      4417


Epoch 00002: val_acc improved from 0.88997 to 0.89201, saving model to /home/homes/jhpark/hate-speech/logs/davidson/hybrid/weights.02.hdf5
18s - loss: 0.2068 - acc: 0.9133 - val_loss: 0.2534 - val_acc: 0.8920
Epoch 4/10
Generating Classification Report:
  32/4417 [..............................] - ETA: 0s 448/4417 [==>...........................] - ETA: 0s 896/4417 [=====>........................] - ETA: 0s1312/4417 [=======>......................] - ETA: 0s1728/4417 [==========>...................] - ETA: 0s2144/4417 [=============>................] - ETA: 0s2560/4417 [================>.............] - ETA: 0s2976/4417 [===================>..........] - ETA: 0s3392/4417 [======================>.......] - ETA: 0s3840/4417 [=========================>....] - ETA: 0s4256/4417 [===========================>..] - ETA: 0s
             precision    recall  f1-score   support

       none       0.84      0.89      0.86      1734
    abusive       0.93      0.89      0.91      2683

avg / total       0.89      0.89      0.89      4417


Epoch 00003: val_acc did not improve
18s - loss: 0.1770 - acc: 0.9292 - val_loss: 0.2617 - val_acc: 0.8895
Epoch 5/10
Generating Classification Report:
  32/4417 [..............................] - ETA: 0s 384/4417 [=>............................] - ETA: 0s 768/4417 [====>.........................] - ETA: 0s1152/4417 [======>.......................] - ETA: 0s1536/4417 [=========>....................] - ETA: 0s1920/4417 [============>.................] - ETA: 0s2304/4417 [==============>...............] - ETA: 0s2688/4417 [=================>............] - ETA: 0s3072/4417 [===================>..........] - ETA: 0s3424/4417 [======================>.......] - ETA: 0s3776/4417 [========================>.....] - ETA: 0s4128/4417 [===========================>..] - ETA: 0s
             precision    recall  f1-score   support

       none       0.84      0.89      0.86      1734
    abusive       0.93      0.89      0.91      2683

avg / total       0.89      0.89      0.89      4417


Epoch 00004: val_acc did not improve
18s - loss: 0.1513 - acc: 0.9403 - val_loss: 0.2755 - val_acc: 0.8891
Training Finished
