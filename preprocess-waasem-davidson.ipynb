{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data.preprocess import load_from_file\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded preprocessed tweets for none:3372\n",
      "loaded preprocessed tweets for abusive:16553\n",
      "loaded preprocessed tweets for none:416\n",
      "loaded preprocessed tweets for abusive:2062\n",
      "loaded preprocessed tweets for none:417\n",
      "loaded preprocessed tweets for abusive:2062\n",
      "loaded preprocessed tweets for none:10376\n",
      "loaded preprocessed tweets for sexism:3152\n",
      "loaded preprocessed tweets for racism:1649\n",
      "loaded preprocessed tweets for none:1297\n",
      "loaded preprocessed tweets for sexism:394\n",
      "loaded preprocessed tweets for racism:206\n",
      "loaded preprocessed tweets for none:1297\n",
      "loaded preprocessed tweets for sexism:395\n",
      "loaded preprocessed tweets for racism:207\n",
      "loaded preprocessed tweets for none:488\n",
      "cannot open split valid\n",
      "cannot open split test\n"
     ]
    }
   ],
   "source": [
    "data_d = load_from_file(\"davidson\", [\"none\",\"abusive\"])\n",
    "data_w = load_from_file(\"waasem\", [\"none\",\"sexism\", \"racism\"])\n",
    "data_relabel = load_from_file(\"relabel\", [\"none\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for data in [data_d, data_w, data_relabel]:\n",
    "    for label in data[\"train\"].keys():\n",
    "        for row in data[\"train\"][label]:\n",
    "            vocab.update(row)\n",
    "            if max_len < len(row):\n",
    "                max_len = len(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_freq = 2\n",
    "count = 0\n",
    "for word in vocab.keys():\n",
    "    if vocab[word] >= min_freq:\n",
    "        count += 1\n",
    "vocab_size = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13479"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_vocab = [\"PAD\", \"UNK\"]\n",
    "for word, _ in vocab.most_common(vocab_size):\n",
    "    _vocab.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id2word = {}\n",
    "word2id = {}\n",
    "for i, word in enumerate(_vocab):\n",
    "    id2word[i] = word\n",
    "    word2id[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 40\n",
    "def tokens2id(tokens):\n",
    "    idx = []\n",
    "    for t in tokens[:max_len]:\n",
    "        if t not in word2id.keys():\n",
    "            idx.append(word2id[\"UNK\"])\n",
    "        else:\n",
    "            idx.append(word2id[t])\n",
    "    padding_needed = max_len - len(idx) if max_len > len(idx) else 0\n",
    "    for _ in range(padding_needed):\n",
    "        idx.append(word2id[\"PAD\"])\n",
    "    assert len(idx) == max_len\n",
    "    return idx\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<user>', 'i', 'have', 'never', 'once', 'in', 'my', 'life', 'been', 'to', 'a', \"'\", 'coffee', 'shop', \"'\", 'like', 'starbucks', '.', 'i', 'am', 'a', 'hick', 'though', '.']\n",
      "[2, 8, 47, 130, 497, 22, 24, 191, 142, 10, 5, 90, 1360, 2246, 90, 34, 3479, 3, 8, 167, 5, 2722, 371, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(data_d[\"train\"][\"none\"][0])\n",
    "print(tokens2id(data_d[\"train\"][\"none\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idx_dataset(data):\n",
    "    idx_data = {}\n",
    "    for key in [\"train\", \"valid\", \"test\"]:\n",
    "        idx_data[key] = {}\n",
    "        for label in tqdm(data[key].keys()):\n",
    "            idx_data[key][label] = list(map(tokens2id, data[key][label]))\n",
    "    return idx_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx_d = idx_dataset(data_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx_w = idx_dataset(data_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx_relabel = idx_dataset(data_relabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_npy(data, name):\n",
    "    file_format = \"./data/word_outputs/%s_%s_%s.npy\"\n",
    "    for key in data.keys():\n",
    "        for label in data[key].keys():\n",
    "            file_name = file_format % (key, label, name)\n",
    "            array = np.array(data[key][label])\n",
    "            np.save(file_name, array)\n",
    "            print(\"Saved in %s. %s\" % (file_name, str(array.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved in ./data/word_outputs/train_racism_waasem.npy. (1649, 40)\n",
      "Saved in ./data/word_outputs/train_none_waasem.npy. (10376, 40)\n",
      "Saved in ./data/word_outputs/train_sexism_waasem.npy. (3152, 40)\n",
      "Saved in ./data/word_outputs/test_racism_waasem.npy. (207, 40)\n",
      "Saved in ./data/word_outputs/test_none_waasem.npy. (1297, 40)\n",
      "Saved in ./data/word_outputs/test_sexism_waasem.npy. (395, 40)\n",
      "Saved in ./data/word_outputs/valid_racism_waasem.npy. (206, 40)\n",
      "Saved in ./data/word_outputs/valid_none_waasem.npy. (1297, 40)\n",
      "Saved in ./data/word_outputs/valid_sexism_waasem.npy. (394, 40)\n"
     ]
    }
   ],
   "source": [
    "save_npy(idx_w, \"waasem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved in ./data/word_outputs/train_abusive_davidson.npy. (16553, 40)\n",
      "Saved in ./data/word_outputs/train_none_davidson.npy. (3372, 40)\n",
      "Saved in ./data/word_outputs/test_abusive_davidson.npy. (2062, 40)\n",
      "Saved in ./data/word_outputs/test_none_davidson.npy. (417, 40)\n",
      "Saved in ./data/word_outputs/valid_abusive_davidson.npy. (2062, 40)\n",
      "Saved in ./data/word_outputs/valid_none_davidson.npy. (416, 40)\n"
     ]
    }
   ],
   "source": [
    "save_npy(idx_d, \"davidson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved in ./data/word_outputs/train_none_relabel.npy. (488, 40)\n"
     ]
    }
   ],
   "source": [
    "save_npy(idx_relabel, \"relabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"./data/word_outputs/vocab.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\"word2id\": word2id, \"id2word\":id2word}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Char preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data.char import text_to_1hot_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def char_idx_dataset(data):\n",
    "    idx_data = {}\n",
    "    for key in [\"train\", \"valid\", \"test\"]:\n",
    "        idx_data[key] = {}\n",
    "        for label in tqdm(data[key].keys()):\n",
    "            idx_data[key][label] = [text_to_1hot_matrix(\" \".join(row)) for row in data[key][label]]\n",
    "    return idx_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "char_idx_d = char_idx_dataset(data_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "char_idx_w = char_idx_dataset(data_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "char_idx_relabel = char_idx_dataset(data_relabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_npy(data, name):\n",
    "    file_format = \"./data/char_outputs/%s_%s_%s.npy\"\n",
    "    for key in data.keys():\n",
    "        for label in data[key].keys():\n",
    "            file_name = file_format % (key, label, name)\n",
    "            array = np.array(data[key][label])\n",
    "            np.save(file_name, array)\n",
    "            print(\"Saved in %s. %s\" % (file_name, str(array.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved in ./data/char_outputs/train_abusive_davidson.npy. (16553, 140, 70)\n",
      "Saved in ./data/char_outputs/train_none_davidson.npy. (3372, 140, 70)\n",
      "Saved in ./data/char_outputs/test_abusive_davidson.npy. (2062, 140, 70)\n",
      "Saved in ./data/char_outputs/test_none_davidson.npy. (417, 140, 70)\n",
      "Saved in ./data/char_outputs/valid_abusive_davidson.npy. (2062, 140, 70)\n",
      "Saved in ./data/char_outputs/valid_none_davidson.npy. (416, 140, 70)\n"
     ]
    }
   ],
   "source": [
    "save_npy(char_idx_d, \"davidson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved in ./data/char_outputs/train_racism_waasem.npy. (1649, 140, 70)\n",
      "Saved in ./data/char_outputs/train_none_waasem.npy. (10376, 140, 70)\n",
      "Saved in ./data/char_outputs/train_sexism_waasem.npy. (3152, 140, 70)\n",
      "Saved in ./data/char_outputs/test_racism_waasem.npy. (207, 140, 70)\n",
      "Saved in ./data/char_outputs/test_none_waasem.npy. (1297, 140, 70)\n",
      "Saved in ./data/char_outputs/test_sexism_waasem.npy. (395, 140, 70)\n",
      "Saved in ./data/char_outputs/valid_racism_waasem.npy. (206, 140, 70)\n",
      "Saved in ./data/char_outputs/valid_none_waasem.npy. (1297, 140, 70)\n",
      "Saved in ./data/char_outputs/valid_sexism_waasem.npy. (394, 140, 70)\n"
     ]
    }
   ],
   "source": [
    "save_npy(char_idx_w, \"waasem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved in ./data/char_outputs/train_none_relabel.npy. (488, 140, 70)\n"
     ]
    }
   ],
   "source": [
    "save_npy(char_idx_relabel, \"relabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  },
  "widgets": {
   "state": {
    "045a7d5d871142a9993af57e4c5dec85": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "05c719211fbb4e7e855e8ecce3dcc11d": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "0ecd3a72a1874a5ab363afaf4bec241a": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "1c4b62f3b18940b4b4cb91bb9f3b8115": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "1f9ece0030994e58977cfa284e343fa9": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "233f93d101ce47619eae4c2702e1c4aa": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "2353c3121acf4dee928d3fa67adc3692": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "2491dfde6313408ab74d53a21f5526c4": {
     "views": [
      {
       "cell_index": 26
      }
     ]
    },
    "32cbd570c920462aae20fa12b8348a70": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "3608bb9fb5924f61b328ec8f9b45e47d": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "5166cbe0626542478672d3c73597ac3e": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "5981f4f6d0be4e239815ec18b0c2ddab": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "5a20ddadf0a540c5a6f0d17fa125e441": {
     "views": [
      {
       "cell_index": 26
      }
     ]
    },
    "5e4eb8e019524c15817b029195902ee5": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "6d7c3d25079b45a0b3c014a01835ed20": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "8179dc434094408e9ccfcf05532e6831": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "828d54c04571419fad25eb832f84b0cc": {
     "views": [
      {
       "cell_index": 26
      }
     ]
    },
    "8c1ec2bb5b174cbb8453d63e9f262b80": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "8ce505536cf848b3a478d1c0ae06095f": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "8f5c1cabbb5e430ba53d2bfec5cc4666": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "a20ee5a864e345b49845efc42a08d44c": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "ac3b622360594de6abf03dc8795c9d88": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "b2f5170b323c46e79afe29b158325c32": {
     "views": [
      {
       "cell_index": 26
      }
     ]
    },
    "cdfe30834ca641dba8b4baff5f5ec111": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "e545e4e8182549199965c46fcd401a33": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "e63c5df73e2049bf87b837ac1a95e42c": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "f082f51623d7456c8ab0b79e55fdd847": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "f1c8f46bdc3a4f2cab65a7f8a70e9fc1": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "f5ad4534e87e4fcfaa8de47b54649472": {
     "views": [
      {
       "cell_index": 26
      }
     ]
    },
    "fa28030a4d1b4181b7c742bf063f31c3": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
