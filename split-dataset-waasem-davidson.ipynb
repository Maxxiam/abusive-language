{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load waasem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from data.preprocess import concat_unshared_task_datasets, preprocess_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unshared task dataset concat done.\n",
      "Label Count: Sexism-3940, Racism-2062, None-12762\n"
     ]
    }
   ],
   "source": [
    "data = concat_unshared_task_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split(data, labels):\n",
    "    _data = {\"train\": {}, \"valid\": {}, \"test\": {}}\n",
    "    for i, key in enumerate(labels):\n",
    "        _data[\"train\"][key], x, _, _ = train_test_split(data[key],\n",
    "                                                              np.zeros_like(data[key]), \n",
    "                                                              test_size=0.2)\n",
    "        train_length = len(_data[\"train\"][key])\n",
    "        _data[\"valid\"][key], _data[\"test\"][key], _, _ = train_test_split(x, np.zeros_like(x), test_size=0.5)\n",
    "        \n",
    "        valid_length = len(_data[\"valid\"][key])\n",
    "        test_length = len(_data[\"test\"][key])\n",
    "        print(\"splitted %s: %s/%s/%s\" % (key, train_length, valid_length, test_length))\n",
    "    return _data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitted none: 10209/1276/1277\n",
      "splitted racism: 1649/206/207\n",
      "splitted sexism: 3152/394/394\n"
     ]
    }
   ],
   "source": [
    "splitted = split(data, [\"none\", \"racism\", \"sexism\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_file(data_name, data):\n",
    "    path = \"./data/preprocessed/\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    for split in data.keys():\n",
    "        for label in data[split].keys():\n",
    "            file_name = \"%s_%s_%s.txt\" % (split, label, data_name)\n",
    "            with open(path + file_name, \"w\") as f:\n",
    "                for tweet in data[split][label]:\n",
    "                    try:\n",
    "                        f.write(\"%s\\n\" % tweet)\n",
    "                    except UnicodeEncodeError:\n",
    "                        print(\"unicode encode error. skipping line\")\n",
    "                print(\"Wrote on %s\" % file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote on valid_racism_waasem.txt\n",
      "Wrote on valid_none_waasem.txt\n",
      "Wrote on valid_sexism_waasem.txt\n",
      "Wrote on train_racism_waasem.txt\n",
      "Wrote on train_none_waasem.txt\n",
      "Wrote on train_sexism_waasem.txt\n",
      "Wrote on test_racism_waasem.txt\n",
      "Wrote on test_none_waasem.txt\n",
      "Wrote on test_sexism_waasem.txt\n"
     ]
    }
   ],
   "source": [
    "save_file(\"waasem\", splitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load davidson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 0 - hate speech 1 - offensive language 2 - neither"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/crawled/davidson.csv\", sep=\",\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @mckayllaa: I wish I had pretty colored eyes .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12681.192027</td>\n",
       "      <td>3.243473</td>\n",
       "      <td>0.280515</td>\n",
       "      <td>2.413711</td>\n",
       "      <td>0.549247</td>\n",
       "      <td>1.110277</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7299.553863</td>\n",
       "      <td>0.883060</td>\n",
       "      <td>0.631851</td>\n",
       "      <td>1.399459</td>\n",
       "      <td>1.113299</td>\n",
       "      <td>0.462089</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6372.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12703.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18995.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25296.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0         count   hate_speech  offensive_language  \\\n",
       "count   24783.000000  24783.000000  24783.000000        24783.000000   \n",
       "unique           NaN           NaN           NaN                 NaN   \n",
       "top              NaN           NaN           NaN                 NaN   \n",
       "freq             NaN           NaN           NaN                 NaN   \n",
       "mean    12681.192027      3.243473      0.280515            2.413711   \n",
       "std      7299.553863      0.883060      0.631851            1.399459   \n",
       "min         0.000000      3.000000      0.000000            0.000000   \n",
       "25%      6372.500000      3.000000      0.000000            2.000000   \n",
       "50%     12703.000000      3.000000      0.000000            3.000000   \n",
       "75%     18995.500000      3.000000      0.000000            3.000000   \n",
       "max     25296.000000      9.000000      7.000000            9.000000   \n",
       "\n",
       "             neither         class  \\\n",
       "count   24783.000000  24783.000000   \n",
       "unique           NaN           NaN   \n",
       "top              NaN           NaN   \n",
       "freq             NaN           NaN   \n",
       "mean        0.549247      1.110277   \n",
       "std         1.113299      0.462089   \n",
       "min         0.000000      0.000000   \n",
       "25%         0.000000      1.000000   \n",
       "50%         0.000000      1.000000   \n",
       "75%         0.000000      1.000000   \n",
       "max         9.000000      2.000000   \n",
       "\n",
       "                                                    tweet  \n",
       "count                                               24783  \n",
       "unique                                              24783  \n",
       "top     RT @mckayllaa: I wish I had pretty colored eyes .  \n",
       "freq                                                    1  \n",
       "mean                                                  NaN  \n",
       "std                                                   NaN  \n",
       "min                                                   NaN  \n",
       "25%                                                   NaN  \n",
       "50%                                                   NaN  \n",
       "75%                                                   NaN  \n",
       "max                                                   NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19190\n",
       "2     4163\n",
       "0     1430\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abusive_text = list(map(preprocess_tweet, df[df[\"class\"] == 1].tweet.tolist())) \n",
    "hate_text = list(map(preprocess_tweet, df[df[\"class\"] == 0].tweet.tolist()))\n",
    "none_text = list(map(preprocess_tweet, df[df[\"class\"] == 2].tweet.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20620"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abusive_text += hate_text\n",
    "len(abusive_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4163"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(none_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitted none: 3330/416/417\n",
      "splitted abusive: 16496/2062/2062\n"
     ]
    }
   ],
   "source": [
    "splitted_davidson = split({\"abusive\": abusive_text, \"none\": none_text}, [\"none\", \"abusive\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote on valid_abusive_davidson.txt\n",
      "Wrote on valid_none_davidson.txt\n",
      "Wrote on train_abusive_davidson.txt\n",
      "Wrote on train_none_davidson.txt\n",
      "Wrote on test_abusive_davidson.txt\n",
      "Wrote on test_none_davidson.txt\n"
     ]
    }
   ],
   "source": [
    "save_file(\"davidson\", splitted_davidson)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
